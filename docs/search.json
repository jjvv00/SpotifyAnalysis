[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring Musical Tastes: A Data Analysis of Spotify Data and Song Moods",
    "section": "",
    "text": "1 Introduction\nEveryone is unique and diverse. Music is a vast and dynamic landscape, and personal preferences and the emotional impact of songs can vary widely from person to person as well. We are in a digital age where streaming services dominate. This allows the availability of extensive music libraries. From these streaming services, APIs open up new avenues for exploring the diverse facets of musical tastes and emotional resonance in numbers.\nAs mentioned earlier, there are a multitude of platforms to stream music. Pandora, Apple Music, YouTube, Amazon, and Spotify are popular choices. In most of these platforms, users are not only listeners. They are the curators of their own musical experiences. In order to help each user curate their experience, these platforms read user data and make recommendations and playlists based on their listening preferences. One of the most popular apps is Spotify, and each year, Spotify releases trends for each user based on their listening pattern for the year called “Spotify Wrapped,” which was recently released! For this project, we will use the “spotifyr” package to access extensive data about songs from our top artists of the year. The “spotifyr” package is useful for developers to analyze the the emotions of an artist’s album and look at some insights of the user. However, we will only use the functions to access the artists’ data.\nOur decision to explore musical preferences through the Spotify R package is motivated by the desire to understand the intersection of personal taste, emotional connection, and shared musical experiences. By comparing the top tracks between two users, we aim to uncover similarities and differences that may reflect diverse musical journeys and influences. While it is unlikely to have an overlap between our top artists and tracks, it is the moods of the artists that could be insightful. Using the valence, energy, and danceability variables from “spotifyr,” we can compare the moods of artists’ albums.\nThis exploration not only contributes to our understanding of the intricacies of musical preferences but also sheds light on the emotional narratives woven into music. By combining data-driven insights from the Spotify R package, we aim to offer a comprehensive perspective on the intersection of personal, emotional, and shared experiences within the realm of music. Through this project, we hope to unravel the richness of musical expression and its profound impact on individual and collective identities."
  },
  {
    "objectID": "data.html#technical-description",
    "href": "data.html#technical-description",
    "title": "2  Data",
    "section": "2.1 Technical Description",
    "text": "2.1 Technical Description\nWe will be accessing the Spotify Web API that provides us to a vast collection of music-related data. This could include information about tracks, albums, artists, and user-specific information. This data is collected and maintained by Spotify, a leading music streaming platform. Thus, we are assuming that Spotify is able to update the API frequently. There are not any obvious issues or problems with the data. We plan to retrieve data through the “spotifyr” R wrapper for pulling track audio features and other information from Spotify’s Web API in bulk (Thompson, Et al., 2022). The authors are Josia Parry, Donal Phipps, Tom Wolf, and Charlie Thompson, who also maintains the package. According to Thomposon’s Github, the last changes are from December 14, 2022.\nOur data is in the form of 4 dataframes, one for each of our top two artists. These data frames contain all of the songs for a specific artist (Taylor Swift, Fleetwood Mac, Doja Cat, and Peso Pluma). There are 39 features listed for each song. These range from basic descriptors such as song title, album, release date, to more complex features to describe the mood/tone of the songs. We will mainly utilize the danceability, energy, and valence scores for each song. The number of rows in each of these data frames is the total number of songs each artist has. Taylor Swift will have a data frame of 530 X 39. Fleetwood Mac has a data frame of size 760 X 39. Doja Cat has a data frame of size 91 X 39, and Peso Pluma has a data frame of size 57 X 39. Since Doja Cat and Peso Pluma have a much smaller discography in comparison to Taylor Swift and Fleetwood Mac, there could be potential limitations and biases towards/against these artists."
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research Plan",
    "text": "2.2 Research Plan\nComparative Analysis of Top Artists:\nWe will analyze the top two artists for each of us provided by our Spotify Wrapped. While there are methods to extract user information from the Spotify API, Spotify recently released Spotify Wrapped as mentioned earlier, so we wanted to use that feature. Based on our Spotify Wrapped, Ellise’s top artists are Taylor Swift, Fleetwood Mac, Queens of the Stone Age, Bruno Mars, and Rihanna. For Jaclyn, her top artists are Doja Cat, Peso Pluma, SZA, Megan Thee Stallion, and Ariana Grande. For this project, we will be comparing the tracks and albums between our top two artists: Taylor Swift, Fleetwood Mac, Doja Cat, and Peso Pluma.\nExploring Album Moods:\nLeveraging the Spotify API’s audio features, particularly valence and energy, we can analyze the mood dynamics of artists’ albums. Valence represents the musical positivity, while energy represents the intensity and activity. By aggregating these features at the album level, we gain insights into the overall emotional content of each album. The Spotify R package allows us to extract and process this information efficiently, enabling us to explore patterns and themes in the emotional landscape of diverse artists. By utilizing the get_audio_features function from the “spotifyr,” we can obtain the valence, danceability, and energy features for each track. Then. we can aggregate these features at the album level to represent the overall mood. Lastly, we can analyze patterns and trends in mood dynamics across different artists’ albums."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing Value Analysis",
    "text": "2.3 Missing Value Analysis\nThe only missing values are in the “track_preview_url” column of the Taylor Swift dataframe.\n\n\nCode\nlibrary(spotifyr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nSys.setenv(SPOTIFY_CLIENT_ID = \"967400701dd14f18a61884b7f6f0656b\", SPOTIFY_CLIENT_SECRET = \"9341a33182d34c1fbc8072ab537131d2\")\n\ntoken &lt;- get_spotify_access_token()\n\n\n\n\nCode\n# For Taylor Swift \nTS &lt;- get_artist_audio_features('taylor swift')\n# TS &lt;- read.csv(\"data/TS.csv\")\n\nNA_countsTS &lt;- colSums(is.na(TS))\n\nna_dataTS &lt;- data.frame(column = names(NA_countsTS), NA_countTS = NA_countsTS)\n\nggplot(na_dataTS, aes(x = column, y = NA_countTS, fill = NA_countTS)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsTS) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Taylor Swift\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) +\n  geom_text(aes(label = NA_countTS), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe.\n\n\nCode\n# For Fleetwood Mac\n\nFM &lt;- get_artist_audio_features('fleetwood mac')\n# FM &lt;- read.csv(\"data/FM.csv\")\n\nNA_countsFM &lt;- colSums(is.na(FM))\n\nna_dataFM &lt;- data.frame(column = names(NA_countsFM), NA_countFM = NA_countsFM)\n\nggplot(na_dataFM, aes(x = column, y = NA_countFM, fill = NA_countFM)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsFM) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Fleetwood Mac\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countFM), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe.\n\n\nCode\n# For Doja Cat\n\nDC &lt;- get_artist_audio_features('doja cat')\n# DC &lt;- read.csv(\"data/DC.csv\")\n\nNA_countsDC &lt;- colSums(is.na(DC))\n\nna_dataDC &lt;- data.frame(column = names(NA_countsDC), NA_countDC = NA_countsDC)\n\nggplot(na_dataDC, aes(x = column, y = NA_countDC, fill = NA_countDC)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsDC) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Doja Cat\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countDC), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe.\n\n\nCode\n# For Peso Pluma\n\nPP &lt;- get_artist_audio_features('peso pluma')\n# PP &lt;- read.csv(\"data/PP.csv\")\n\nNA_countsPP &lt;- colSums(is.na(PP))\n\nna_dataPP &lt;- data.frame(column = names(NA_countsPP), NA_countPP = NA_countsPP)\n\nggplot(na_dataPP, aes(x = column, y = NA_countPP, fill = NA_countPP)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsPP) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Peso Pluma\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countPP), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "4 Citations:\n(paper and image) Helmholz, P., Meyer, M., & Robra-Bissantz, S. (2019, June 12). Feel the Moosic: Emotion-based Music Selection and Recommendation. https://doi.org/10.18690/978-961-286-280-0.11"
  },
  {
    "objectID": "results.html#average-energy-valence-danceability-comparisons-between-our-top-artists",
    "href": "results.html#average-energy-valence-danceability-comparisons-between-our-top-artists",
    "title": "3  Results",
    "section": "3.1 Average energy, valence, danceability % comparisons between our top artists",
    "text": "3.1 Average energy, valence, danceability % comparisons between our top artists\nGet all required libraries:\n\n\nCode\nlibrary(spotifyr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(tidyr)\nlibrary(broom)\n\n\n\nAttaching package: 'broom'\n\nThe following object is masked from 'package:spotifyr':\n\n    tidy\n\n\nIn order to access Spotify’s data, you must set up a Spotify Dev account. Once you do, you will get a client ID and client secret:\n\n\nCode\nSys.setenv(SPOTIFY_CLIENT_ID = \"967400701dd14f18a61884b7f6f0656b\", SPOTIFY_CLIENT_SECRET = \"9341a33182d34c1fbc8072ab537131d2\")\ntoken &lt;- get_spotify_access_token()\n\n\nCreate a dataframe for each artist’s song collection using the spotifyr package’s “get_artist_audio_features”. This function produces dataframes with all of each artist’s songs and multiple features about each song. We will only be using the “artist_name”, “album_release_date”, “danceability”, “valence”, “energy”, “track_name”, “album_name” features so we will remove the rest of them at this point. Then, we can download these dataframes as .csv files.\n\n\nCode\nTS &lt;- get_artist_audio_features('taylor swift')\nFM &lt;- get_artist_audio_features('fleetwood mac')\nDC &lt;- get_artist_audio_features('doja cat')\nPP &lt;- get_artist_audio_features('peso pluma')\n\n# Save the data frames as CSV files\nTS &lt;- subset(TS, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nFM &lt;- subset(FM, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nDC &lt;- subset(DC, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nPP &lt;- subset(PP, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\n\n# Code to save subset data to desktop\n# desktop_path &lt;- file.path(Sys.getenv(\"HOME\"), \"Desktop\")\n# write.csv(TS, file.path(desktop_path, \"TS.csv\"))\n# write.csv(FM, file.path(desktop_path, \"FM.csv\"))\n# write.csv(DC, file.path(desktop_path, \"DC.csv\"))\n# write.csv(PP, file.path(desktop_path, \"PP.csv\"))\n\n# Display a message indicating the successful save\n# cat(\"Data frames have been saved to:\", desktop_path, \"\\n\")\n\n\nFirst, find the average energy across all of the songs for each artist separately. Then create a new dataframe with all four of these energy averages. We will display this data using a bar graph.\n\n\nCode\nTSenergy_avg &lt;- mean(TS$energy) #2274A5\nFMenergy_avg &lt;- mean(FM$energy) #F75C03\nDCenergy_avg &lt;- mean(DC$energy) #D90368\nPPenergy_avg &lt;- mean(PP$energy) #F1C40F\n\nenergy_sums = c(TSenergy_avg, FMenergy_avg, DCenergy_avg, PPenergy_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\nenergy_data = data.frame(Label = labels, Value = energy_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\n\nggplot(energy_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average energy of songs (%)\", breaks = seq(0, 1, by = 0.1)) + \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Energy\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\nEllise’s top two artists overall tend to have lower energy songs than Jaclyn’s top artists, although they are all pretty close on average.\nRepeat this process for the valence and danceability:\n\n\nCode\nTSvalence_avg &lt;- mean(TS$valence) \nFMvalence_avg &lt;- mean(FM$valence) \nDCvalence_avg &lt;- mean(DC$valence)\nPPvalence_avg &lt;- mean(PP$valence)\n\nvalence_sums = c(TSvalence_avg, FMvalence_avg, DCvalence_avg, PPvalence_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\nvalence_data = data.frame(Label = labels, Value = valence_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\nggplot(valence_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average valence of songs (%)\", breaks = seq(0, 1, by = 0.1))+ \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Valence\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\nSince Peso Pluma and Doja Cat have the first and third highest valence scores, overall, it appears that Jaclyn likes music with a higher valence slightly more than Ellise does.\n\n\nCode\nTSdanceability_avg &lt;- mean(TS$danceability) \nFMdanceability_avg &lt;- mean(FM$danceability) \nDCdanceability_avg &lt;- mean(DC$danceability) \nPPdanceability_avg &lt;- mean(PP$danceability) \n\ndanceability_sums = c(TSdanceability_avg, FMdanceability_avg, DCdanceability_avg, PPdanceability_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\ndanceability_data = data.frame(Label = labels, Value = danceability_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\nggplot(danceability_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average danceability of songs (%)\", breaks = seq(0, 1, by = 0.1)) + \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Danceability\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\nSince Doja Cat and Peso Pluma are Jaclyn’s top artists, this indicates that she prefers more danceable music than Ellise. However, this is a bit surprising considering Ellise is a dancer!\nNow we will compare the moods of each artist based on the moods of each of their songs. This is based on James Russell’s circumplex model as referenced in “Feel the Moosic: Emotion-based Music Selection and Recommendation” by Patrick Helmholz, Michael Meyer, Susanne Robra-Bissantz. In this paper, they classify songs into one of four different mood categories (happy, angry, sad, or relaxed) based on their energy and valence scores. We will use this model to display the most frequent song moods for each of our top artists. This should help us compare the moods of our music preferences.\n\n\nCode\n# Mutate data: add an extra column \"quadrant\" to hold the mood of the song based on its energy/valence\nTS &lt;- TS %&gt;%\n  mutate(\n    quadrant = case_when(\n      valence &gt;= 0.5 & energy &gt;= 0.5 ~ \"Happy\",\n      valence &lt; 0.5 & energy &gt;= 0.5 ~ \"Angry\",\n      valence &lt; 0.5 & energy &lt; 0.5 ~ \"Sad\",\n      TRUE ~ \"Relaxed\"\n    )\n  )\n\nquadrant_colors &lt;- c(\n  \"Happy\" = \"green3\",\n  \"Angry\" = \"#FA0000CF\",\n  \"Sad\" = \"#8D6A9F\",\n  \"Relaxed\" = \"#63D2FF\"\n)\n\nggplot(TS, aes(x = valence, y = energy, color = quadrant)) +\n  geom_point(size = 1) +\n  xlim(0, 1) + ylim(0, 1) +  \n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +  \n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  labs(\n    title = expression(\"Scatter Plot of the Mood of Every\" ~ bold(\"Taylor Swift\") ~ \"Song \"), subtitle = \"Calculated based on the energy/valence of each song\",\n    x = \"Valence\",\n    y = \"Energy\",\n    color = \"Artist\") +\n  scale_color_manual(values = quadrant_colors) +\n  theme(legend.position = \"right\")\n\n\n\n\n\nIt appears that the majority of Taylor Swift’s songs are angry and happy. This makes sense as her songs are typically very passionate and have a strong message. However, I question how well these calculations can be trusted because using this method, her song “I Knew You Were Trouble.” was classified as relaxed when it should definitely be considered angry.\n\n\nCode\nFM &lt;- FM %&gt;%\n  mutate(\n    quadrant = case_when(\n      valence &gt;= 0.5 & energy &gt;= 0.5 ~ \"Happy\",\n      valence &lt; 0.5 & energy &gt;= 0.5 ~ \"Angry\",\n      valence &lt; 0.5 & energy &lt; 0.5 ~ \"Sad\",\n      TRUE ~ \"Relaxed\"\n    )\n  )\n\nquadrant_colors &lt;- c(\n  \"Happy\" = \"green3\",\n  \"Angry\" = \"#FA0000CF\",\n  \"Sad\" = \"#8D6A9F\",\n  \"Relaxed\" = \"#63D2FF\"\n)\n\nggplot(FM, aes(x = valence, y = energy, color = quadrant)) +\n  geom_point(size = 1) +\n  xlim(0, 1) + ylim(0, 1) +  \n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +  \n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  labs(\n    title = expression(\"Scatter Plot of the Mood of Every\" ~ bold(\"Fleetwood Mac\") ~ \"Song \"), subtitle = \"Calculated based on the energy/valence of each song\",\n    x = \"Valence\",\n    y = \"Energy\",\n    color = \"Artist\") +\n  scale_color_manual(values = quadrant_colors) +\n  theme(legend.position = \"right\")\n\n\n\n\n\nFleetwood Mac appears to have a pretty even distribution of moods across their songs. This makes sense because they have the most songs out of all artists in our study and they have been making music over many decades. It appears that they have the most happy songs overall.\n\n\nCode\nDC &lt;-DC %&gt;%\n  mutate(\n    quadrant = case_when(\n      valence &gt;= 0.5 & energy &gt;= 0.5 ~ \"Happy\",\n      valence &lt; 0.5 & energy &gt;= 0.5 ~ \"Angry\",\n      valence &lt; 0.5 & energy &lt; 0.5 ~ \"Sad\",\n      TRUE ~ \"Relaxed\"\n    )\n  )\n\nquadrant_colors &lt;- c(\n  \"Happy\" = \"green3\",\n  \"Angry\" = \"#FA0000CF\",\n  \"Sad\" = \"#8D6A9F\",\n  \"Relaxed\" = \"#63D2FF\"\n)\n\nggplot(DC, aes(x = valence, y = energy, color = quadrant)) +\n  geom_point(size = 1) +\n  xlim(0, 1) + ylim(0, 1) +  \n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +  \n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  labs(\n    title = expression(\"Scatter Plot of the Mood of Every\" ~ bold(\"Doja Cat\") ~ \"Song \"), subtitle = \"Calculated based on the energy/valence of each song\",\n    x = \"Valence\",\n    y = \"Energy\",\n    color = \"Artist\") +\n  scale_color_manual(values = quadrant_colors) +\n  theme(legend.position = \"right\")\n\n\n\n\n\nImmediately, looking at this plot I notice how many fewer songs Doja Cat has compared to Taylor Swift and Fleetwood Mac. Although the majority of them appear to be angry or happy, the difference in the sample sizes between artists makesit harder to compare them. This information was not visible to us in the bar graphs.\n\n\nCode\nPP &lt;- PP %&gt;%\n  mutate(\n    quadrant = case_when(\n      valence &gt;= 0.5 & energy &gt;= 0.5 ~ \"Happy\",\n      valence &lt; 0.5 & energy &gt;= 0.5 ~ \"Angry\",\n      valence &lt; 0.5 & energy &lt; 0.5 ~ \"Sad\",\n      TRUE ~ \"Relaxed\"\n    )\n  )\n\nquadrant_colors &lt;- c(\n  \"Happy\" = \"green3\",\n  \"Angry\" = \"#FA0000CF\",\n  \"Sad\" = \"#8D6A9F\",\n  \"Relaxed\" = \"#63D2FF\"\n)\n\nggplot(PP, aes(x = valence, y = energy, color = quadrant)) +\n  geom_point(size = 1) +\n  xlim(0, 1) + ylim(0, 1) +  \n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +  \n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  labs(\n    title = expression(\"Scatter Plot of the Mood of Every\" ~ bold(\"Peso Pluma\") ~ \"Song \"), subtitle = \"Calculated based on the energy/valence of each song\",\n    x = \"Valence\",\n    y = \"Energy\",\n    color = \"Artist\") +\n  scale_color_manual(values = quadrant_colors) +\n  theme(legend.position = \"right\")\n\n\n\n\n\nAgain, like Doja Cat, Peso Pluma has very few songs. The large majority of them are considered happy.\nUnfortunately, we don’t have access to our exact listening histories. However, we can try to predict our listening trends based on the release dates of songs from our top artists. This of course isn’t fully accurate because most of Fleetwood Mac’s songs were released before we were born.\n\n\nCode\nTS$album_release_date &lt;- as.Date(TS$album_release_date)\n\n# Calculate average values for each release date\naverage_data &lt;- TS %&gt;%\n  group_by(album_release_date) %&gt;%\n  summarise(avg_energy = mean(energy),\n            avg_valence = mean(valence),\n            avg_danceability = mean(danceability))\n\nggplot(average_data, aes(x = album_release_date)) +\n  geom_point(aes(y = avg_energy, color = \"Energy\")) +\n  geom_point(aes(y = avg_valence, color = \"Valence\")) +\n  geom_point(aes(y = avg_danceability, color = \"Danceability\")) +\n  geom_line(aes(y = avg_energy, color = \"Energy\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_valence, color = \"Valence\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_danceability, color = \"Danceability\"), linewidth = 0.6) +\n  labs(title = expression(\"Average Energy, Valence, and Danceability Over Time of\" ~ bold(\"Taylor Swift's\") ~ \"Songs\"),\n       x = \"Release date\",\n       y = \"Average value per date\",\n       color = \"Variable\") +\n  scale_x_date(date_breaks = \"2 year\", date_labels = \"%Y\") +\n  scale_color_manual(values = c(\"Energy\" = \"red\", \"Valence\" = \"blue\", \"Danceability\" = \"green\")) + \n  theme(title = element_text(size = 9.5), axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 10)), \n  )\n\n\n\n\n\nThe most notable trends in this plot are the low average danceability, valence, and energy values around the years 2020-2022. This is really interesting because this is around the same time as the COVID-19 pandemic.\n\n\nCode\nFM$album_release_date &lt;- as.Date(FM$album_release_date)\n\n# Some NAs are introduced when as.Date is called. This is because only the year of their release is listed. We will omit them because we cannot work with them and we have plenty of data. \nFM &lt;- na.omit(FM)\n\n# Calculate average values for each release date\naverage_data &lt;- FM %&gt;%\n  group_by(album_release_date) %&gt;%\n  summarise(avg_energy = mean(energy),\n            avg_valence = mean(valence),\n            avg_danceability = mean(danceability))\n\nggplot(average_data, aes(x = album_release_date)) +\n  geom_point(aes(y = avg_energy, color = \"Energy\")) +\n  geom_point(aes(y = avg_valence, color = \"Valence\")) +\n  geom_point(aes(y = avg_danceability, color = \"Danceability\")) +\n  geom_line(aes(y = avg_energy, color = \"Energy\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_valence, color = \"Valence\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_danceability, color = \"Danceability\"), linewidth = 0.6) +\n  labs(title = expression(\"Average Energy, Valence, and Danceability Over Time of\" ~ bold(\"Fleetwood Mac's\") ~ \"Songs\"),\n       x = \"Release date\",\n       y = \"Average value per date\",\n       color = \"Variable\") +\n  scale_x_date(date_breaks = \"2 year\", date_labels = \"%Y\") +\n  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +\n  scale_color_manual(values = c(\"Energy\" = \"red\", \"Valence\" = \"blue\", \"Danceability\" = \"green\")) + \n  theme(title = element_text(size = 9.5), axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 10)), \n  )\n\n\n\n\n\nThis plot is all over the place. Fleetwood Mac has a very large list of songs, many with very different sounds. Luckily, for the task of comparing Ellise and Jaclyn’s music tastes over time, this plot wouldn’t be very useful anyway. Many Fleetwood Mac songs came out before they were both born, so we couldn’t use it to get an idea of Ellise’s music preference.\n\n\nCode\nDC$album_release_date &lt;- as.Date(DC$album_release_date)\n\n# Calculate average values for each release date\naverage_data &lt;- DC %&gt;%\n  group_by(album_release_date) %&gt;%\n  summarise(avg_energy = mean(energy),\n            avg_valence = mean(valence),\n            avg_danceability = mean(danceability))\n\nggplot(average_data, aes(x = album_release_date)) +\n  geom_point(aes(y = avg_energy, color = \"Energy\")) +\n  geom_point(aes(y = avg_valence, color = \"Valence\")) +\n  geom_point(aes(y = avg_danceability, color = \"Danceability\")) +\n  geom_line(aes(y = avg_energy, color = \"Energy\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_valence, color = \"Valence\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_danceability, color = \"Danceability\"), linewidth = 0.6) +\n  labs(title = expression(\"Average Energy, Valence, and Danceability Over Time of\" ~ bold(\"Doja Cat's\") ~ \"Songs\"),\n       x = \"Release date\",\n       y = \"Average value per date\",\n       color = \"Variable\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +\n  scale_color_manual(values = c(\"Energy\" = \"red\", \"Valence\" = \"blue\", \"Danceability\" = \"green\")) + \n  theme(title = element_text(size = 9.5), axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 10)), \n  )\n\n\n\n\n\nContrary to Taylor Swift, Doja Cat appears to have released songs with high average danceability, valence, and energy values around the years 2020-2022. Assuming this mimics Jaclyn’s listening habits, we could say that she and Ellise had different ways of using music to cope with the pandemic. Unfortunately, the limited amount of data for Doja Cat makes it hard to learn much else.\n\n\nCode\nPP$album_release_date &lt;- as.Date(PP$album_release_date)\n\n# Some NAs are introduced when as.Date is called. This is because only the year of their release is listed. We will omit them because we cannot work with them. \nPP &lt;- na.omit(PP)\n\n# Calculate average values for each release date\naverage_data &lt;- PP %&gt;%\n  group_by(album_release_date) %&gt;%\n  summarise(avg_energy = mean(energy),\n            avg_valence = mean(valence),\n            avg_danceability = mean(danceability))\n\nggplot(average_data, aes(x = album_release_date)) +\n  geom_point(aes(y = avg_energy, color = \"Energy\")) +\n  geom_point(aes(y = avg_valence, color = \"Valence\")) +\n  geom_point(aes(y = avg_danceability, color = \"Danceability\")) +\n  geom_line(aes(y = avg_energy, color = \"Energy\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_valence, color = \"Valence\"), linewidth = 0.6) +\n  geom_line(aes(y = avg_danceability, color = \"Danceability\"), linewidth = 0.6) +\n  labs(title = expression(\"Average Energy, Valence, and Danceability Over Time of\" ~ bold(\"Peso Pluma's\") ~ \"Songs\"),\n       x = \"Release date\",\n       y = \"Average value per date\",\n       color = \"Variable\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +\n  scale_color_manual(values = c(\"Energy\" = \"red\", \"Valence\" = \"blue\", \"Danceability\" = \"green\")) + \n  theme(title = element_text(size = 9.5), axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 10)), \n  )\n\n\n\n\n\nAgain, due to the limited data available for Peso Pluma’s songs, it’s hard for us to learn much from this plot. Over time, we can loosely say that his songs became more danceable, energetic, and had higher valences. However, overall, these scores remained relatively the same over the years (between 0.5-0.8)."
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "This graph will visualize the three primary variables we have been studying: valence, danceability, and energy. Each song of each artist is plotted on the graph in their respective colors:\nTaylor Swift: Blue\nFleetwood Mac: Orange\nDoja Cat: Pink\nPeso Pluma: Yellow\nTo interact with the D3 graph, hover over each circle to reveal detailed information about a specific track. The size of the circles corresponds to the energy level of the tracks, with larger circles indicating higher energy. The x-axis represents danceability, while the y-axis represents valence. Explore the graph to discover patterns and trends in how these musical features vary across tracks from different artists. The association of the artists to their respective color makes it easier to identify their contributions to the overall visualization. Additionally, the title “Spotify Analysis: Danceability vs. Valence” provides context for the graph’s purpose. Use the axis labels to understand the scale and meaning of the plotted data. Enjoy exploring the Spotify analysis visualization!"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "5  Conclusion",
    "section": "",
    "text": "In our exploration, we explored Ellise’s and Jaclyn’s top artists of 2023—Taylor Swift, Fleetwood Mac, Doja Cat, and Peso Pluma—analyzing their moods using Spotify’s ‘sportifyr’ wrapper and variables like energy, valence, and danceability in order to compare their musical preferences. The energy levels among artists were relatively close, with Peso Pluma leading at 0.65 and Fleetwood Mac trailing at 0.56. Danceability showed minor variations, with Doja Cat at 0.74 and Fleetwood Mac at 0.55. Valence differed more significantly, revealing a trend in Jaclyn’s preference for upbeat and happy songs compared to Ellise.\nWe employed James Russell’s circumplex model to categorize songs into moods based on energy and valence. Jaclyn’s playlist leaned towards happy or angry, while Ellise embraced a broader spectrum of moods, albeit with variations in artists’ song counts impacting our conclusions.\nAttempting to visualize our listening habits over time, we made the assumption that we listened to songs upon release. This suggested Ellise favored lower danceability, valence, and energy during the pandemic, while Jaclyn did the opposite. However, this assumption limits the scope, especially for older artists like Fleetwood Mac.\nThe D3 interactive graph highlighted challenges due to varying discography sizes, with Taylor Swift and Fleetwood Mac dominating. While both shared danceability and energy distributions, Fleetwood Mac trended higher in valence. Doja Cat, with a smaller discography, showcased high danceability and varying valence. Peso Pluma clustered in the top-middle, indicating high danceability and valence, with energy variations. Comparing artists, Jaclyn’s tended towards higher valence and danceability, while Ellise’s displayed a broader range of moods.\nLooking ahead, accessing personal Spotify data would enhance precision, allowing us to analyze our actual listening habits. Expanding to more artists and exploring additional variables or R wrappers could provide deeper insights. While obtaining direct access to the Spotify API posed challenges, it remains a potential source for richer information. Through this exploration, we gained valuable insights into Spotify’s API and R packages for extracting music data."
  }
]