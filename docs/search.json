[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring Musical Tastes: A Data Analysis of Spotify Data and Song Moods",
    "section": "",
    "text": "1 Introduction\nEveryone is unique and diverse. Music is a vast and dynamic landscape, and personal preferences and the emotional impact of songs can vary widely from person to person as well. We are in a digital age where streaming services dominate. This allows the availability of extensive music libraries. From these streaming services, APIs open up new avenues for exploring the diverse facets of musical tastes and emotional resonance in numbers.\nAs mentioned earlier, there are a multitude of platforms to stream music. Pandora, Apple Music, YouTube, Amazon, and Spotify are popular choices. In most of these platforms, users are not only listeners. They are the curators of their own musical experiences. In order to help each user curate their experience, these platforms read user data and make recommendations and playlists based on their listening preferences. One of the most popular apps is Spotify, and each year, Spotify releases trends for each user based on their listening pattern for the year called “Spotify Wrapped,” which was recently released! For this project, we will use the “spotifyr” package to access extensive data about songs from our top artists of the year. The “spotifyr” package is useful for developers to analyze the the emotions of an artist’s album and look at some insights of the user. However, we will only use the functions to access the artists’ data.\nOur decision to explore musical preferences through the Spotify R package is motivated by the desire to understand the intersection of personal taste, emotional connection, and shared musical experiences. By comparing the top tracks between two users, we aim to uncover similarities and differences that may reflect diverse musical journeys and influences. While it is unlikely to have an overlap between our top artists and tracks, it is the moods of the artists that could be insightful. Using the valence, energy, and danceability variables from “spotifyr,” we can compare the moods of artists’ albums.\nThis exploration not only contributes to our understanding of the intricacies of musical preferences but also sheds light on the emotional narratives woven into music. By combining data-driven insights from the Spotify R package, we aim to offer a comprehensive perspective on the intersection of personal, emotional, and shared experiences within the realm of music. Through this project, we hope to unravel the richness of musical expression and its profound impact on individual and collective identities."
  },
  {
    "objectID": "data.html#technical-description",
    "href": "data.html#technical-description",
    "title": "2  Data",
    "section": "2.1 Technical Description",
    "text": "2.1 Technical Description\nWe will be accessing the Spotify Web API that provides us to a vast collection of music-related data. This could include information about tracks, albums, artists, and user-specific information. This data is collected and maintained by Spotify, a leading music streaming platform. Thus, we are assuming that Spotify is able to update the API frequently. There are not any obvious issues or problems with the data. We plan to retrieve data through the “spotifyr” R wrapper for pulling track audio features and other information from Spotify’s Web API in bulk (Thompson, Et al., 2022). The authors are Josia Parry, Donal Phipps, Tom Wolf, and Charlie Thompson, who also maintains the package. According to Thomposon’s Github, the last changes are from December 14, 2022.\nOur data is in the form of 4 dataframes, one for each of our top two artists. These data frames contain all of the songs for a specific artist (Taylor Swift, Fleetwood Mac, Doja Cat, and Peso Pluma). There are 39 features listed for each song. These range from basic descriptors such as song title, album, release date, to more complex features to describe the mood/tone of the songs. We will mainly utilize the danceability, energy, and valence scores for each song. The number of rows in each of these data frames is the total number of songs each artist has. Taylor Swift will have a data frame of 530 X 39. Fleetwood Mac has a data frame of size 760 X 39. Doja Cat has a data frame of size 91 X 39, and Peso Pluma has a data frame of size 57 X 39."
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research Plan",
    "text": "2.2 Research Plan\nComparative Analysis of Top Artists:\nWe will analyze the top two artists for each of us provided by our Spotify Wrapped. While there are methods to extract user information from the Spotify API, Spotify recently released Spotify Wrapped as mentioned earlier, so we wanted to use that feature. Based on our Spotify Wrapped, Ellise’s top artists are Taylor Swift, Fleetwood Mac, Queens of the Stone Age, Bruno Mars, and Rihanna. For Jaclyn, her top artists are Doja Cat, Peso Pluma, SZA, Megan Thee Stallion, and Ariana Grande. For this project, we will be comparing the tracks and albums between our top two artists: Taylor Swift, Fleetwood Mac, Doja Cat, and Peso Pluma.\nExploring Album Moods:\nLeveraging the Spotify API’s audio features, particularly valence and energy, we can analyze the mood dynamics of artists’ albums. Valence represents the musical positivity, while energy represents the intensity and activity. By aggregating these features at the album level, we gain insights into the overall emotional content of each album. The Spotify R package allows us to extract and process this information efficiently, enabling us to explore patterns and themes in the emotional landscape of diverse artists. By utilizing the get_audio_features function from the “spotifyr,” we can obtain the valence, danceability, and energy features for each track. Then. we can aggregate these features at the album level to represent the overall mood. Lastly, we can analyze patterns and trends in mood dynamics across different artists’ albums."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing Value Analysis",
    "text": "2.3 Missing Value Analysis\nThe only missing values are in the “track_preview_url” column of the Taylor Swift dataframe.\n\n\nCode\nlibrary(spotifyr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nSys.setenv(SPOTIFY_CLIENT_ID = \"d895b3472cb743c581bc155bd97d3c4e\", SPOTIFY_CLIENT_SECRET = \"348918affcf741d8841b9445b693c0d4\")\n\ntoken &lt;- get_spotify_access_token()\n\n\n\n\nCode\n# For Taylor Swift \nTS &lt;- get_artist_audio_features('taylor swift')\n\nNA_countsTS &lt;- colSums(is.na(TS))\n\nna_dataTS &lt;- data.frame(column = names(NA_countsTS), NA_countTS = NA_countsTS)\n\nggplot(na_dataTS, aes(x = column, y = NA_countTS, fill = NA_countTS)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  labs(title = \"Count of NAs in Each Column for Taylor Swift\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) +\n  geom_text(aes(label = NA_countTS), vjust = -0.5, size = 3)\n\n\n\n\n\nAs you can see here, every element of the “track_preview_url” column is NA. However, this won’t be a problem because we are not using this feature for our project. We will remove it from all dataframes.\n\n\nCode\n# For Fleetwood Mac\nFM &lt;- get_artist_audio_features('fleetwood mac')\n\nNA_countsFM &lt;- colSums(is.na(FM))\n\nna_dataFM &lt;- data.frame(column = names(NA_countsFM), NA_countFM = NA_countsFM)\n\nggplot(na_dataFM, aes(x = column, y = NA_countFM, fill = NA_countFM)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsFM) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Fleetwood Mac\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countFM), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe.\n\n\nCode\n# For Doja Cat\nDC &lt;- get_artist_audio_features('doja cat')\n\nNA_countsDC &lt;- colSums(is.na(DC))\n\nna_dataDC &lt;- data.frame(column = names(NA_countsDC), NA_countDC = NA_countsDC)\n\nggplot(na_dataDC, aes(x = column, y = NA_countDC, fill = NA_countDC)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsDC) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Doja Cat\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countDC), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe.\n\n\nCode\n# For Peso Pluma\nPP &lt;- get_artist_audio_features('peso pluma')\nView(PP)\n\nNA_countsPP &lt;- colSums(is.na(PP))\n\nna_dataPP &lt;- data.frame(column = names(NA_countsPP), NA_countPP = NA_countsPP)\n\nggplot(na_dataPP, aes(x = column, y = NA_countPP, fill = NA_countPP)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_y_continuous(limits = c(0, max(NA_countsPP) + 1)) +\n  labs(title = \"Count of NAs in Each Column for Peso Pluma\", x = \"Column\", y = \"Number of NA Values\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(size = 8, angle = 50, hjust = 1)) + \n  geom_text(aes(label = NA_countPP), vjust = -0.5, size = 3)\n\n\n\n\n\nThere are no NA values in this dataframe."
  },
  {
    "objectID": "results.html#average-energy-valence-danceability-comparisons-between-our-top-artists",
    "href": "results.html#average-energy-valence-danceability-comparisons-between-our-top-artists",
    "title": "3  Results",
    "section": "3.1 Average energy, valence, danceability % comparisons between our top artists",
    "text": "3.1 Average energy, valence, danceability % comparisons between our top artists\nGet all required libraries:\n\n\nCode\nlibrary(spotifyr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(tidyr)\nlibrary(broom)\n\n\n\nAttaching package: 'broom'\n\nThe following object is masked from 'package:spotifyr':\n\n    tidy\n\n\nIn order to access Spotify’s data, you must set up a Spotify Dev account. Once you do, you will get a client ID and client secret:\n\n\nCode\nSys.setenv(SPOTIFY_CLIENT_ID = \"d895b3472cb743c581bc155bd97d3c4e\", SPOTIFY_CLIENT_SECRET = \"348918affcf741d8841b9445b693c0d4\")\ntoken &lt;- get_spotify_access_token()\n\n\nCreate a dataframe for each artist’s song collection using the spotifyr package’s “get_artist_audio_features”. This function produces dataframes with all of each artist’s songs and multiple features about each song. We will only be using the “artist_name”, “album_release_date”, “danceability”, “valence”, “energy”, “track_name”, “album_name” features so we will remove the rest of them at this point. Then, we can download these dataframes as .csv files.\n\n\nCode\nTS &lt;- get_artist_audio_features('taylor swift')\nFM &lt;- get_artist_audio_features('fleetwood mac')\nDC &lt;- get_artist_audio_features('doja cat')\nPP &lt;- get_artist_audio_features('peso pluma')\n\ndesktop_path &lt;- file.path(Sys.getenv(\"HOME\"), \"Desktop\")\n\n# Save the data frames as CSV files\nTS &lt;- subset(TS, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nFM &lt;- subset(FM, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nDC &lt;- subset(DC, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\nPP &lt;- subset(PP, select = c(\"artist_name\", \"album_release_date\", \"danceability\", \"valence\", \"energy\", \"track_name\", \"album_name\"))\n\n\nwrite.csv(TS, file.path(desktop_path, \"TS.csv\"))\nwrite.csv(FM, file.path(desktop_path, \"FM.csv\"))\nwrite.csv(DC, file.path(desktop_path, \"DC.csv\"))\nwrite.csv(PP, file.path(desktop_path, \"PP.csv\"))\n\n# Display a message indicating the successful save\ncat(\"Data frames have been saved to:\", desktop_path, \"\\n\")\n\n\nData frames have been saved to: /Users/jaclynvu/Desktop \n\n\nFirst, find the average energy across all of the songs for each artist separately. Then create a new dataframe with all four of these energy averages. We will display this data using a bar graph.\n\n\nCode\nTSenergy_avg &lt;- mean(TS$energy) #2274A5\nFMenergy_avg &lt;- mean(FM$energy) #F75C03\nDCenergy_avg &lt;- mean(DC$energy) #D90368\nPPenergy_avg &lt;- mean(PP$energy) #F1C40F\n\nenergy_sums = c(TSenergy_avg, FMenergy_avg, DCenergy_avg, PPenergy_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\nenergy_data = data.frame(Label = labels, Value = energy_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\n\nggplot(energy_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average energy of songs (%)\", breaks = seq(0, 1, by = 0.1)) + \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Energy\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\nRepeat this process for the valence and danceability:\n\n\nCode\nTSvalence_avg &lt;- mean(TS$valence) \nFMvalence_avg &lt;- mean(FM$valence) \nDCvalence_avg &lt;- mean(DC$valence)\nPPvalence_avg &lt;- mean(PP$valence)\n\nvalence_sums = c(TSvalence_avg, FMvalence_avg, DCvalence_avg, PPvalence_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\nvalence_data = data.frame(Label = labels, Value = valence_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\nggplot(valence_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average valence of songs (%)\", breaks = seq(0, 1, by = 0.1))+ \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Valence\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\n\n\nCode\nTSdanceability_avg &lt;- mean(TS$danceability) \nFMdanceability_avg &lt;- mean(FM$danceability) \nDCdanceability_avg &lt;- mean(DC$danceability) \nPPdanceability_avg &lt;- mean(PP$danceability) \n\ndanceability_sums = c(TSdanceability_avg, FMdanceability_avg, DCdanceability_avg, PPdanceability_avg)\nlabels = c(\"Taylor Swift\", \"Fleetwood Mac\", \"Doja Cat\", \"Peso Pluma\")\n\ndanceability_data = data.frame(Label = labels, Value = danceability_sums)\n\nartist_colors &lt;- c(\"Taylor Swift\" = \"#2274A5\", \n                    \"Fleetwood Mac\" = \"#F75C03\", \n                    \"Doja Cat\" = \"#D90368\", \n                    \"Peso Pluma\" = \"#F1C40F\")\n\nggplot(danceability_data, aes(x = fct_rev(fct_reorder(Label, Value)), y = Value, fill = Label)) + \n  geom_bar(stat = \"identity\", color = \"black\") +\n  scale_x_discrete(name = \"Artist\") + \n  scale_y_continuous(name = \"Average danceability of songs (%)\", breaks = seq(0, 1, by = 0.1)) + \n  labs(title = expression(\"Comparison of the\" ~ bold(\"Danceability\") ~ \"of Songs from Our Top Artists\")) +\n  scale_fill_manual(values = artist_colors) + \n  theme(\n    axis.title.y = element_text(margin = margin(r = 15)),  \n    axis.title.x = element_text(margin = margin(t = 12))\n  )\n\n\n\n\n\nNow we will compare the moods of each artist based on the moods of each of their songs. This is based on James Russell’s circumplex model as referenced in “Feel the Moosic: Emotion-based Music Selection and Recommendation” by Patrick Helmholz, Michael Meyer, Susanne Robra-Bissantz. In this paper, they classify songs into one of four different mood categories (happy, angry, sad, or relaxed) based on their energy and valence scores. We will use this model to display the most frequent song moods for each of our top artists. This should help us compare the moods of our music preferences.\n\n\nCode\n# Mutate data: add an extra column \"quadrant\" to hold the mood of the song based on its energy/valence\nTS &lt;- TS %&gt;%\n  mutate(\n    quadrant = case_when(\n      valence &gt;= 0.5 & energy &gt;= 0.5 ~ \"Happy\",\n      valence &lt; 0.5 & energy &gt;= 0.5 ~ \"Angry\",\n      valence &lt; 0.5 & energy &lt; 0.5 ~ \"Sad\",\n      TRUE ~ \"Relaxed\"\n    )\n  )\n\nquadrant_colors &lt;- c(\n  \"Happy\" = \"green3\",\n  \"Angry\" = \"#FA0000CF\",\n  \"Sad\" = \"#8D6A9F\",\n  \"Relaxed\" = \"#63D2FF\"\n)\n\nggplot(TS, aes(x = valence, y = energy, color = quadrant)) +\n  geom_point(size = 1) +\n  xlim(0, 1) + ylim(0, 1) +  \n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +  \n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  labs(\n    title = \"Scatter Plot of Valence vs. Energy in Taylor Swift's songs\", subtitle = \"Each quartile represents a different mood\",\n    x = \"Valence\",\n    y = \"Energy\",\n    color = \"Artist\") +\n  scale_color_manual(values = quadrant_colors) +\n  theme(legend.position = \"right\")\n\n\n\n\n\n#Citations:\n(paper and image) Helmholz, P., Meyer, M., & Robra-Bissantz, S. (2019, June 12). Feel the Moosic: Emotion-based Music Selection and Recommendation. https://doi.org/10.18690/978-961-286-280-0.11"
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "This graph will visualize the three primary variables we have been studying: valence, danceability, and energy. Each song of each artist is plotted on the graph in their respective colors:\nTaylor Swift: Blue\nFleetwood Mac: Orange\nDoja Cat: Pink\nPeso Pluma: Yellow\nTo interact with the D3 graph, hover over each circle to reveal detailed information about a specific track. The size of the circles corresponds to the energy level of the tracks, with larger circles indicating higher energy. The x-axis represents danceability, while the y-axis represents valence. Explore the graph to discover patterns and trends in how these musical features vary across tracks from different artists. The association of the artists and a color makes it easy to identify their contributions to the overall visualization. However, for Peso Pluma and Doja Cat, who have less tracks comparable to Taylor Swift and Fleetwood Mac, it can be difficult to identify those points. Additionally, the title “Spotify Analysis: Danceability vs. Valence” provides context for the graph’s purpose. Use the axis labels to understand the scale and meaning of the plotted data. Enjoy exploring the Spotify analysis visualization!"
  }
]